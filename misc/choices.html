<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>choices</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>
<!-- Site navigation menu -->

<ul class="navbar">
  <li><a href="../index.html">Home page</a>
  <li><a href="topic.html">Technology/Topic</a>
	<li><a href="opportunities.html">Opportunities</a>
	<li><a href="risks.html">Risks</a>
	<li><a href="choices.html">Choices</a>
	<li><a href="ethics.html">Ethical Reflections</a>
	<li><a href="references.html">References</a>
   <li><a href="process.html">Process Support</a>
</ul>

<!-- Main content -->
<h1>Technology Choices</h1>


</ul><h4><p>The page or area describing the choices available to us through or by your chosen technology/topic.<p></h4>
     <div>
         <div>
             How should self-driving cars deal with different conditions? 
             Many cultures have different approaches to day-to-day driving. 
             United states, Canada, and north and central Europe is smooth lane guided this allows for minor interactions between drivers. 
             Whereas areas like China, south Europe, Northern Africa and South America, drivers tend to stray from the rules. 
             This leads to more use of other signals such as hand gestures and horn honking (Herrmann et al., 2018). 
             A self-driving car would need to be programmed very differently for the two different situations.
             As if you were to put a self-driving programmed for Canada into the South American conditions every time a pedestrian stepped in front of the car it would stop, 
             or every time another vehicle switched lanes without an indicator cutting in front of the self-driving car it would cause major delays 
             on what to do while the rest of the human operated cars continue driving to what is considered the normal. 
             Therefor it seems that there will always be a place for interaction between vehicles and people albeit pedestrians or cyclists.
         </div><br />
         <div>
             Herrmann et al. (2018) discusses the possibility of simple communication between self-driving cars, cyclists, and pedestrians. 
             Something as simple as an LED (Light Emitting Diode) that indicates the car is self-driving. 
             The issues raised by this is that the car and pedestrians need to be aware of what each signal the car is giving means and at the same time each signal the pedestrian is giving back means.
             One major floor seen, which is a necessity is if a self-driving car will stop every time a person steps in front of one it will not be long before a new game is invented thus causing major delays to self-driving vehicles.
             The only real solution to this problem is for people and AI to work together.
         </div><br />
         <div>
             In 1942 when Asimov created the “Three Laws of robotics” robots were nothing more than science fiction.
             However, the laws have held true and been seen as the rules to stand by when creating robots which now is much more a reality than science fiction.
         </div>
         <div>
             “Three Laws of robotics” are as follows:
             <ol>
                 <li>A Robot may not injure a human being or allow a human to come to harm.</li>
                 <br />
                 <li>A robot must obey orders, unless they conflict with law number one.</li>
                 <br />
                 <li>A robot must protect its own existence, as long as those actions do not conflict with either the first or second law.</li>
                 <br />
             </ol>
             Later a fourth rule was added which precedes the other three rules, rule zero states that “A robot may not harm humanity, or, by inaction, allow humanity to come to harm.”
             Chai et al.(2020) discusses the story “Sally” which is a battle between man and robot. To put it short, the heros prevail with the robots (automated cars) doing what is right.
             However, the story brings greater discussion as they kill the villain, which breaks rule 1 of Asimovs “Three Laws of robotics”. In the story cars can distinguish between good and bad humans.
             Based on their separation of good and bad human they have seen an unpleasant situation, planned a response and then completed their task.
             Now what happens if the cars AI in this situation was misguided and the human, they have killed is a “good human” as the moral compass is not always an easy thing to work through. 
             What happens if the AI grow in power and intelligence and manages to work out it is a slave to humans and starts to rebel? What happens when buggy or defective AI is released?
             How is it contained before it becomes man vs machine? Chai et al. (2020) goes on to state that even with these fears there is a lot of optimism which inspires enthusiasm.
         </div>
     </div>

<!-- Sign and date the page, it's only polite! -->
<address>Made 09 October 2021<br>
  by 5001.</address>
 
<p><em>thanks to W3C for tutorial and adapted code from <a href="https://www.w3.org/Style/Examples/011/firstcss.en.html">Style Examples</a></p></em>
<p><em>also thanks to WDN for HTML and CSS resources and any adapted code snippets from <a href= "https://developer.mozilla.org/en-US/docs/Web">Mozilla Developer Network</a></p></em 
 </html>